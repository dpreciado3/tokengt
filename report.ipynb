{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approximating Second-Order Equivariant Basis\n",
    "\n",
    "The paper argues that the proposed TokenGT model is at least as expressive as the second-order Invariant Graph Network. This is, it can approximate order-k permutation equivariant linear layers. To prove this experimentally, a multihead self-attention layer is used and its head-wise attention scores are supervised to approximate equivariant basis tensors by minimizing L2 loss. Synthetic Barab√°si-Albert random graphs are generated for this, the equivariant basis approximations are tested with random unseen graphs.\n",
    "\n",
    "According to the paper, self-attention achieves accurate approximation of equivariant basis when orthonormal node identifiers and type idenfifiers are given. This is the results table provided by the paper, which we will try to reproduce:\n",
    "\n",
    "<img src=\"./images/basis_table.png\" alt=\"basisapprox\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large-Scale Graph Learning\n",
    "\n",
    "The regression capabilities of TokenGT are tested with the PCQM4Mv2 quantum chemistry regression dataset. According to the paper, both ORF and Laplacian versions of TokenGT achieve performance better than all GNN baselines, but are slightly weaker than Transformers with graph-specific modifications. These are the results we will try to reproduce:\n",
    "\n",
    "<img src=\"./images/chem_table.png\" alt=\"chemregression\" width=\"50%\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "## Code quality\n",
    "## Challenges\n",
    "## Possible extensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
